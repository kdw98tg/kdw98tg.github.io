---
title: "[AI] 앙상블(Ensemble)기법과 배깅(Bagging), 부스팅(Boosting), 스태킹(Stacking) 기법"

categories:
  - AI
  
tags:
  - [AI, Ensemble]

toc: true
toc_sticky: true

published: true

date: 2025-10-24
last_modified_at: 2025-10-24
---

## 앙상블이란?

머신러닝을 위한 다양한 학습 알고리즘들을 결합하여 학습시키는 것으로, 예측력의 보완은 물론, 각자의 알고리즘을 단일로 사용할 경우 나타나는 단점들을 보완해 주는 기법입니다.

앙상블 기법은 큰 추상적인 개념이고, 구체적인 방법으로는 배깅(Bagging), 부스팅(Boosting), 스태킹(Stacking)등이 있습니다.

## 배깅(Bagging)

Bagging는 그 자체로 뜻이 있는 단어가 아닙니다. Bagging은 (**B**ootstrap **agg**regat**ing**) 의 약자 입니다. 즉, 부트스트랩들을 집계한다 라는 뜻으로 해석할 수 있습니다.

그렇다면 우선, Bootstrap 이 뭔지부터 알아야 합니다.

Bootstrap은 통계학에서 사용하는 용어로, 랜덤으로 샘플들을 뽑는 기법을 이야기 합니다. 만약, 공장의 불량품률이 몇이나 되는지를 측정하는 문제가 있다고 합시다. 모든 부품들을 다 꺼내어 불량검사를 하는것은 굉장히 비효율적인 일입니다. 여기에 `Bootstrap`개념을 적용하면, 약 100개의 샘플 상품들을 뽑은 뒤, 100개중에 불량품을 추출해내게 됩니다. 그리고 또 랜덤으로 약 100개의 샘플 상품들을 뽑은 뒤, 100개중에 불량품의 비율을 계산하게 됩니다. 그리고, 그 군집들의 불량품률을 계산하여 평균을 내면, 그 공장의 불량품률에 통계학적인 수치가 나옵니다.

이것을 머신러닝에 적용하게 되면, 적은 데이터 양으로도 학습 데이터를 늘릴 수 있습니다. 랜덤으로 적은 양의 데이터에서 군집을 형성하고, 그 군집에서 학습된 수치를 평균 내주면 되는 것이죠.

즉, Bagging은 Bootstrap을 집계 하여 학습 데이터가 충분하지 않더라도 충분한 학습효과를 주어 높은 bias의 과소적합 문제나, 높은 variance로 인한 overfiting 문제를 해결하는데 도움을 줍니다.

그걸 그림으로 표현하면 다음과 같습니다.

![](/images/Pasted%20image%2020251024182512.png)

대표적인 Bagging 기법을 사용한 알고리즘이 랜덤 포레스트(Random Forest) 입니다.

## 부스팅(Boosting)

부스팅은 