LightGBM
XGBoost
GradientBoost
부스팅 알고리즘
앙상블이란
decision Tree란
랜덤 포레스트란

EMA 지표
MACD 지표

RSI 지표
Stochastic

Bollinger Band
ATR

OBV
거래량 이동평균


로그 수익률을 사용하는 이유
회귀 : 다음 기간의 로그 수익률 (log(Close_t+1 / Close_t))
분류 : 상승/하락 여부 (0,1)

시프트하여 라벨 생성

**시계열 검증(CV)**

- K-Fold 대신 **롤링/확장 윈도우** 방식:
    
    - 첫 구간 학습 → 다음 구간 검증 → 점점 확장.
        
    - 데이터 누수 방지 위해 `gap`을 넣기도 함.


### **5. 피처 스케일링**

- ElasticNet, LogisticRegression 등은 스케일링 필요.
    
- LightGBM은 스케일링 불필요하지만 데이터 정규화는 품질에 도움.
    
- 일반적으로 `RobustScaler` 또는 `StandardScaler` 사용.


//////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////
## **BTC 예측 모델 구축 시퀀스**

### **1. 데이터 준비**

1. **원천 데이터 확보**
    
    - Binance API 또는 엑셀/CSV에서 BTCUSDT 가격 데이터 다운로드 (1D, 4H, 1W 등).
        
    - 필요한 컬럼: 날짜/시간, 시가(Open), 고가(High), 저가(Low), 종가(Close), 거래량(Volume).
        
2. **전처리**
    
    - 문자열을 datetime으로 변환, 정렬.
        
    - 숫자형으로 변환(`pd.to_numeric`), 결측치 제거.
        
    - 타임존 일관성 유지(tz-naive로 저장하면 모델 처리에 편함).
        

---

### **2. 기술적 지표 생성**

1. **지표 클래스 작성** (`TechnicalIndicatorCalculator`)
    
    - 추세: EMA, MACD
        
    - 모멘텀: RSI, Stochastic
        
    - 변동성: Bollinger Band 폭, ATR
        
    - 거래량: OBV, 거래량 이동평균
        
2. **각 지표를 데이터프레임에 추가**
    
    - 지표마다 파라미터(기간, 윈도우) 적용.
        
    - 결측치가 있는 앞부분은 제거.
        
3. **지표 데이터 저장**
    
    - CSV 또는 Excel 파일로 저장 (모델 학습 시 재활용 가능).
        

---

### **3. 타깃 변수 생성**

1. **예측 목표 정의**
    
    - 회귀: `다음 기간의 로그 수익률` (`log(Close_t+1 / Close_t)`).
        
    - 분류: `상승/하락 여부` (`>0`이면 1, 아니면 0).
        
2. **시프트하여 라벨 생성**
    
    - 미래 값이므로 `.shift(-1)` 같은 방식 사용.
        

---

### **4. 데이터 분할**

1. **학습 구간과 테스트 구간 분리**
    
    - 예: 2019~2022 → 학습, 2023 이후 → 테스트.
        
2. **시계열 검증(CV)**
    
    - K-Fold 대신 **롤링/확장 윈도우** 방식:
        
        - 첫 구간 학습 → 다음 구간 검증 → 점점 확장.
            
        - 데이터 누수 방지 위해 `gap`을 넣기도 함.
            

---

### **5. 피처 스케일링**

- ElasticNet, LogisticRegression 등은 스케일링 필요.
    
- LightGBM은 스케일링 불필요하지만 데이터 정규화는 품질에 도움.
    
- 일반적으로 `RobustScaler` 또는 `StandardScaler` 사용.
    

---

### **6. 모델 학습**

1. **LightGBM (트리 기반)**
    
    - 결측치 자동 처리, 비선형 관계 잘 잡음.
        
    - 하이퍼파라미터: `num_leaves`, `min_data_in_leaf`, `subsample`, `colsample_bytree`.
        
2. **ElasticNet / LogisticRegression (선형)**
    
    - 베이스라인, 피처 영향도 해석 가능.
        
    - 알파(l1,l2) 규제로 과적합 방지.
        

---

### **7. 검증 & 평가**

1. **회귀 지표**
    
    - MAE, RMSE, R² 등으로 성능 측정.
        
2. **분류 지표**
    
    - 정확도, ROC-AUC, F1, Precision/Recall.
        
3. **CV 평균과 테스트셋 성능 비교**
    
    - 과적합 여부 확인.
        

---

### **8. 해석(XAI)**

1. **Feature Importance**
    
    - LightGBM 내장 중요도.
        
2. **SHAP / LIME**
    
    - 어떤 지표가 예측에 영향을 많이 주었는지 확인.
        
    - 시간별·지표별 영향도 시각화.
        

---

### **9. 실험 반복**

- 지표 조합 실험: EMA만 → EMA+MACD → RSI 추가 등.
    
- 시간 프레임별 실험: 4시간봉 / 일봉 / 월봉 비교.
    
- 하이퍼파라미터 튜닝: LightGBM, ElasticNet 각각 최적화.
    

---

### **10. 결과 정리**

- 테이블화: 지표 조합별 성능 변화.
    
- 그래프화: SHAP으로 해석.
    
- 결론: 어떤 지표와 시간 프레임이 효과적인지.